{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Aprendiendo redes neuronales con ChatGPT**\n",
        "*Dorys Trujillo Beltrán*\n",
        "\n",
        "*04 noviembre 2023*"
      ],
      "metadata": {
        "id": "_qNc3JNaRVcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. En la clase de Machine Learning nos dan el siguente código que pertenece a un perceptrón.**"
      ],
      "metadata": {
        "id": "s9D8Kj6bSLTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpbfqrWkU06p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132b5b9d-8e3d-4937-8927-69fc3c5d0e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : [0, 0] Output : 0\n",
            "Input : [0, 1] Output : 0\n",
            "Input : [1, 0] Output : 0\n",
            "Input : [1, 1] Output : 1\n"
          ]
        }
      ],
      "source": [
        "# Unidad mas pequeña de una red neuronal\n",
        "def perceptron(x1,x2):\n",
        "    v = x1 + x2 - 1.2\n",
        "    if v < 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "X = [[0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]]\n",
        "\n",
        "for n in range(4):\n",
        "    y = perceptron(X[n][0],X[n][1])\n",
        "    print('Input :', X[n], 'Output :', y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construcción del perceptrón con paquete de Python**\n",
        "\n",
        "Interpretación del output generada por GPT:\n",
        "* Para la primera entrada [0, 0], el perceptrón produce una salida de 0.\n",
        "* Para la segunda entrada [0, 1], el perceptrón también produce una salida de 0.\n",
        "* Para la tercera entrada [1, 0], el perceptrón nuevamente produce una salida de 0.\n",
        "* Para la cuarta entrada [1, 1], el perceptrón produce una salida de 1."
      ],
      "metadata": {
        "id": "cfFf4lMLTUhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def perceptron2(Xmat):\n",
        "    W = np.array([1, 1])\n",
        "    V = Xmat @ W.T - 1.2\n",
        "    Y = list(map(lambda x: 0 if x<0 else 1, V))\n",
        "    return Y\n",
        "\n",
        "print('Output', perceptron2(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9LXr2pGUAyB",
        "outputId": "016a1443-d5b3-4797-a4fe-58ed6564c9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output [0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Ahora tengo el siguiente ejemplo**"
      ],
      "metadata": {
        "id": "Rl_H74_mVvF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neuron(Xmat, W, b):\n",
        "    V = Xmat @ W.T + b\n",
        "    return list(map(lambda x: 0 if x<0 else 1, V))\n",
        "\n",
        "def MLP_XOR(Xmat):\n",
        "    W1 = np.array([1, 1])\n",
        "    b1 = -1.5\n",
        "    Y1 = neuron(Xmat, W1, b1)\n",
        "    W2 = np.array([1, 1])\n",
        "    b2 = -0.5\n",
        "    Y2 = neuron(Xmat, W2, b2)\n",
        "    X3 = np.c_[Y1, Y2]\n",
        "    W3 = np.array([-2, 1])\n",
        "    b3 = -0.5\n",
        "    return neuron(X3, W3, b3)\n",
        "\n",
        "MLP_XOR(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm48Es99VuZs",
        "outputId": "198f58b8-458d-4a69-ad23-acedf7dddc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Ahora me plantean el siguiente ejercicio:**\n",
        "\n",
        "Modifique la función anterior de modo que utilice ReLU y funciones de activación sigmoidea de las neuronas en la capa oculta y la capa de salida, respectivamente. Verifique si la nueva arquitectura todavía implementa un XOR."
      ],
      "metadata": {
        "id": "cnIlccHpYB_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Código generado por GPT modificado para que cumpla con lo que el ejercicio pide\n",
        "import math   #Libreria\n",
        "\n",
        "def sigmoid(v):  #definiendo función de activación sigmoidea\n",
        "    return 1 / (1+math.exp(-v))\n",
        "\n",
        "\n",
        "def relu(v):  #definiendo función de activación relu\n",
        "    return np.max(v, 0)\n",
        "\n",
        "\n",
        "def neuron(Xmat, W, b, activation = 'relu'): # función de la neurona con pesos y determinando relu con func de activación\n",
        "    V = Xmat @ W.T + b\n",
        "    if activation == 'sigmoid':     #se introduce un condicional para determinar las salidas dependiendo la func de activación\n",
        "      Y = [sigmoid(v) for v in V]\n",
        "    else:\n",
        "      Y = [relu(v) for v in V]\n",
        "    return Y\n",
        "\n",
        "def MLP_XOR(Xmat):\n",
        "    W1 = np.array([1, 1])\n",
        "    b1 = -1.5\n",
        "    Y1 = neuron(Xmat, W1, b1)\n",
        "    W2 = np.array([1,1])   #definiendo el peso 2 que a GPT le faltó\n",
        "    b2 = -0.5\n",
        "    Y2 = neuron(Xmat, W2, b2)\n",
        "\n",
        "    X3= np.c_[Y1, Y2]\n",
        "    W3 = np.array([-2,1])\n",
        "    b3= -0.5\n",
        "\n",
        "    return neuron(X3, W3, b3, activation = 'sigmoid')\n",
        "\n",
        "MLP_XOR(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RNslP2WYCjm",
        "outputId": "32f06ad6-62c8-46a2-d85d-65124acaf789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8807970779778823, 0.7310585786300049, 0.7310585786300049, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:**\n",
        "\n",
        "ChatGPT me ayudó a entender las líneas de código de los ejemplos que el profesor de Machine Learning nos da en clase, que solo con la clase no lo logré entender y además a fortalecer mi comprensión con código en python."
      ],
      "metadata": {
        "id": "FKPZb5AliTl9"
      }
    }
  ]
}